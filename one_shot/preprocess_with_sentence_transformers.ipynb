{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1",
   "metadata": {},
   "source": [
    "# Resume Processing with Sentence Transformers (BERT)\n",
    "This notebook processes resume data from UpdatedResumeDataSet.csv using sentence-transformers to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw resume dataset\n",
    "raw_data = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "print(f\"Total resumes: {len(raw_data)}\")\n",
    "print(f\"\\nColumns: {raw_data.columns.tolist()}\")\n",
    "print(f\"\\nCategory distribution:\")\n",
    "print(raw_data['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3",
   "metadata": {},
   "source": [
    "## Initialize Sentence Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentence transformer model (same as used in backend)\n",
    "print(\"Loading sentence-transformers model: all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded. Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean resume text for better embedding quality\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Replace newlines with spaces\n",
    "    text = text.replace('\\n', ' ').replace('\\\\n', ' ')\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Clean all resume texts\n",
    "raw_data['Resume_Cleaned'] = raw_data['Resume'].apply(clean_text)\n",
    "\n",
    "# Check for empty resumes\n",
    "empty_resumes = raw_data[raw_data['Resume_Cleaned'] == '']\n",
    "print(f\"Empty resumes after cleaning: {len(empty_resumes)}\")\n",
    "\n",
    "# Show sample cleaned text\n",
    "print(f\"\\nSample cleaned text (first 500 chars):\\n{raw_data['Resume_Cleaned'][0][:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings in batches for efficiency\n",
    "print(f\"Starting embedding generation at {datetime.now()}\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "batch_size = 32\n",
    "embeddings_list = []\n",
    "\n",
    "for i in range(0, len(raw_data), batch_size):\n",
    "    batch_texts = raw_data['Resume_Cleaned'][i:i+batch_size].tolist()\n",
    "    batch_embeddings = model.encode(batch_texts, show_progress_bar=False)\n",
    "    embeddings_list.append(batch_embeddings)\n",
    "    \n",
    "    if (i // batch_size + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + len(batch_texts)}/{len(raw_data)} resumes\")\n",
    "\n",
    "# Concatenate all embeddings\n",
    "embeddings = np.vstack(embeddings_list)\n",
    "\n",
    "print(f\"\\nCompleted embedding generation at {datetime.now()}\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6",
   "metadata": {},
   "source": [
    "## Create Processed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with embeddings\n",
    "# Store embeddings as separate columns for each dimension\n",
    "embedding_dim = embeddings.shape[1]\n",
    "\n",
    "# Create column names for embeddings\n",
    "embedding_columns = [f'embedding_{i}' for i in range(embedding_dim)]\n",
    "\n",
    "# Create dataframe with original data\n",
    "processed_data = pd.DataFrame({\n",
    "    'resume_id': range(len(raw_data)),\n",
    "    'category': raw_data['Category'],\n",
    "    'resume_text': raw_data['Resume_Cleaned']\n",
    "})\n",
    "\n",
    "# Add embedding columns\n",
    "embedding_df = pd.DataFrame(embeddings, columns=embedding_columns)\n",
    "processed_data = pd.concat([processed_data, embedding_df], axis=1)\n",
    "\n",
    "print(f\"Processed data shape: {processed_data.shape}\")\n",
    "print(f\"Columns: {len(processed_data.columns)}\")\n",
    "print(f\"  - Metadata columns: 3 (resume_id, category, resume_text)\")\n",
    "print(f\"  - Embedding columns: {embedding_dim}\")\n",
    "\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Resume text length statistics:\")\n",
    "text_lengths = processed_data['resume_text'].str.len()\n",
    "print(f\"  Mean: {text_lengths.mean():.0f} characters\")\n",
    "print(f\"  Median: {text_lengths.median():.0f} characters\")\n",
    "print(f\"  Min: {text_lengths.min()} characters\")\n",
    "print(f\"  Max: {text_lengths.max()} characters\")\n",
    "\n",
    "print(f\"\\nEmbedding statistics:\")\n",
    "embedding_cols = [col for col in processed_data.columns if col.startswith('embedding_')]\n",
    "embedding_values = processed_data[embedding_cols].values\n",
    "print(f\"  Mean: {embedding_values.mean():.4f}\")\n",
    "print(f\"  Std: {embedding_values.std():.4f}\")\n",
    "print(f\"  Min: {embedding_values.min():.4f}\")\n",
    "print(f\"  Max: {embedding_values.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_csv = 'processed_resumes_with_embeddings.csv'\n",
    "processed_data.to_csv(output_csv, index=False)\n",
    "print(f\"Saved processed data to: {output_csv}\")\n",
    "print(f\"File size: {os.path.getsize(output_csv) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings separately as numpy array for faster loading\n",
    "output_npy = 'resume_embeddings.npy'\n",
    "np.save(output_npy, embeddings)\n",
    "print(f\"Saved embeddings to: {output_npy}\")\n",
    "print(f\"File size: {os.path.getsize(output_npy) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata separately (without embeddings)\n",
    "metadata_df = processed_data[['resume_id', 'category', 'resume_text']].copy()\n",
    "output_metadata = 'resume_metadata.csv'\n",
    "metadata_df.to_csv(output_metadata, index=False)\n",
    "print(f\"Saved metadata to: {output_metadata}\")\n",
    "print(f\"File size: {os.path.getsize(output_metadata) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete data as pickle for easy loading\n",
    "output_pickle = 'processed_resumes_complete.pkl'\n",
    "with open(output_pickle, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'metadata': metadata_df,\n",
    "        'embeddings': embeddings,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'model_name': 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "        'processed_date': datetime.now().isoformat()\n",
    "    }, f)\n",
    "print(f\"Saved complete data to: {output_pickle}\")\n",
    "print(f\"File size: {os.path.getsize(output_pickle) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9",
   "metadata": {},
   "source": [
    "## Verify Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the saved data\n",
    "print(\"Testing data loading...\\n\")\n",
    "\n",
    "# Load CSV\n",
    "test_csv = pd.read_csv(output_csv)\n",
    "print(f\"CSV loaded: {test_csv.shape}\")\n",
    "\n",
    "# Load numpy embeddings\n",
    "test_npy = np.load(output_npy)\n",
    "print(f\"NumPy embeddings loaded: {test_npy.shape}\")\n",
    "\n",
    "# Load pickle\n",
    "with open(output_pickle, 'rb') as f:\n",
    "    test_pickle = pickle.load(f)\n",
    "print(f\"Pickle loaded:\")\n",
    "print(f\"  - Metadata: {test_pickle['metadata'].shape}\")\n",
    "print(f\"  - Embeddings: {test_pickle['embeddings'].shape}\")\n",
    "print(f\"  - Model: {test_pickle['model_name']}\")\n",
    "print(f\"  - Processed: {test_pickle['processed_date']}\")\n",
    "\n",
    "print(\"\\nâœ“ All files saved and verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PROCESSING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total resumes processed: {len(processed_data)}\")\n",
    "print(f\"Embedding model: sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Categories: {processed_data['category'].nunique()}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  1. {output_csv} - Full data with embeddings\")\n",
    "print(f\"  2. {output_npy} - Embeddings only (NumPy array)\")\n",
    "print(f\"  3. {output_metadata} - Metadata only (no embeddings)\")\n",
    "print(f\"  4. {output_pickle} - Complete data (Python pickle)\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
